name: "mistral_instruct"
backend: "python"

max_batch_size: 8

input [
  {
    name: "PROMPT"
    data_type: TYPE_STRING
    dims: [1]
  }
]

output [
  {
    name: "OUTPUT"
    data_type: TYPE_STRING
    dims: [1]
  }
]

instance_group [
  {
    kind: KIND_GPU
  }
]

parameters: {
  key: "source"
  value: { string_value: "vllm" }
}

parameters: {
  key: "model_id"
  value: { string_value: "OpenAccessAI/OpenHermes-2.5-Mistral-7B-AWQ" }
}
